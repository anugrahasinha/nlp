{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Norwegian Spell Corrector\n",
    "#### Author : Anugraha Sinha\n",
    "#### Email : anugraha[dot]sinha[at]gmail[dot]com\n",
    "\n",
    "We use the **Project Gutenberg EBook of The Adventures of Sherlock Holmes by Sir Arthur Conan Doyle** as the base document to build a large vocab of english words. We can use some other vocab source as well (May be like wikipedia article dump etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:04:36.614294Z",
     "start_time": "2019-03-15T11:04:36.608289Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to convert all words to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:04:37.329827Z",
     "start_time": "2019-03-15T11:04:37.325825Z"
    }
   },
   "outputs": [],
   "source": [
    "def words(document):\n",
    "    \"Convert text to lower case and tokenise the document\"\n",
    "    return re.findall(r'\\w+', document.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building a frequency information for all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:04:38.970220Z",
     "start_time": "2019-03-15T11:04:38.157187Z"
    }
   },
   "outputs": [],
   "source": [
    "all_words = Counter(words(open('big_doc_for_spelling_correction.txt').read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### example : check frequency for a random word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:04:39.504568Z",
     "start_time": "2019-03-15T11:04:39.489555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check frequency of a random word, say, 'chair'\n",
    "all_words['chair']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example : check top 10 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:04:40.565306Z",
     "start_time": "2019-03-15T11:04:40.544290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 79809),\n",
       " ('of', 40024),\n",
       " ('and', 38312),\n",
       " ('to', 28765),\n",
       " ('in', 22023),\n",
       " ('a', 21124),\n",
       " ('that', 12512),\n",
       " ('he', 12401),\n",
       " ('was', 11410),\n",
       " ('it', 10681)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at top 10 frequent words\n",
    "all_words.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the edit_one function, so as to calculate\n",
    "\n",
    "1 step correction based on following operations\n",
    "1. delete\n",
    "2. insert\n",
    "3. replace\n",
    "4. transpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:04:41.665815Z",
     "start_time": "2019-03-15T11:04:41.655808Z"
    }
   },
   "outputs": [],
   "source": [
    "def edits_one(word):\n",
    "    \"Create all edits that are one edit away from `word`.\"\n",
    "    alphabets    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])                   for i in range(len(word) + 1)]\n",
    "    deletes    = [left + right[1:]                       for left, right in splits if right]\n",
    "    inserts    = [left + c + right                       for left, right in splits for c in alphabets]\n",
    "    replaces   = [left + c + right[1:]                   for left, right in splits if right for c in alphabets]\n",
    "    transposes = [left + right[1] + right[0] + right[2:] for left, right in splits if len(right)>1]\n",
    "    return set(deletes + inserts + replaces + transposes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building edit_two function, which is basically checking execution of edit_one twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:04:42.522772Z",
     "start_time": "2019-03-15T11:04:42.518767Z"
    }
   },
   "outputs": [],
   "source": [
    "def edits_two(word):\n",
    "    \"Create all edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits_one(word) for e2 in edits_one(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check if the given words are known words (present in vocab) or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:04:43.272956Z",
     "start_time": "2019-03-15T11:04:43.269954Z"
    }
   },
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    \"The subset of `words` that appear in the `all_words`.\"\n",
    "    return set(word for word in words if word in all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**possible_correction** based on \n",
    "1. if the word is already present in vocab\n",
    "2. if the word is edit_one (1 edit distance) away from a known word (set of possible words)\n",
    "3. if the word is edit_two (2 edit distance) away from a known word (set of possible words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:04:44.603121Z",
     "start_time": "2019-03-15T11:04:44.598113Z"
    }
   },
   "outputs": [],
   "source": [
    "def possible_corrections(word):\n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits_one(word)) or known(edits_two(word)) or [word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**prob**\n",
    "\n",
    "probability value of the suggested word, based on the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:04:45.694450Z",
     "start_time": "2019-03-15T11:04:45.687448Z"
    }
   },
   "outputs": [],
   "source": [
    "def prob(word, N=sum(all_words.values())): \n",
    "    \"Probability of `word`: Number of appearances of 'word' / total number of tokens\"\n",
    "    return all_words[word] / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example :\n",
    "Checking the possible correction for mis-spelled word \"emfasize\" or \"emfasis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:05:33.279376Z",
     "start_time": "2019-03-15T11:05:32.987959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emphasize'}\n",
      "{'emphasis'}\n"
     ]
    }
   ],
   "source": [
    "print(possible_corrections(\"emfasize\"))\n",
    "print(possible_corrections(\"emfasis\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example:\n",
    "\n",
    "edit_one execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:05:48.967619Z",
     "start_time": "2019-03-15T11:05:48.963617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'money', 'monkey'}\n"
     ]
    }
   ],
   "source": [
    "print(known(edits_one(\"monney\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:05:50.752952Z",
     "start_time": "2019-03-15T11:05:50.660137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51013\n",
      "{'money', 'monkey'}\n"
     ]
    }
   ],
   "source": [
    "# Let's look at words that are two edits away\n",
    "print(len(set(edits_two(\"monney\"))))\n",
    "print(known(edits_one(\"monney\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example:\n",
    "\n",
    "correction for word \"monney\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:05:51.823386Z",
     "start_time": "2019-03-15T11:05:51.818387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'money', 'monkey'}\n"
     ]
    }
   ],
   "source": [
    "# Let's look at possible corrections of a word\n",
    "print(possible_corrections(\"monney\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example:\n",
    "\n",
    "execution for calculating probability if the word is correct or incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:05:53.196249Z",
     "start_time": "2019-03-15T11:05:53.189243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002922233626303688\n",
      "5.378344097491451e-06\n"
     ]
    }
   ],
   "source": [
    "# Let's look at probability of a word\n",
    "print(prob(\"money\"))\n",
    "print(prob(\"monkey\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final function to execute spell correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:05:54.209352Z",
     "start_time": "2019-03-15T11:05:54.203346Z"
    }
   },
   "outputs": [],
   "source": [
    "def spell_check(word):\n",
    "    \"Print the most probable spelling correction for `word` out of all the `possible_corrections`\"\n",
    "    correct_word = max(possible_corrections(word), key=prob)\n",
    "    if correct_word != word:\n",
    "        return \"Did you mean \" + correct_word + \"?\"\n",
    "    else:\n",
    "        return \"Correct spelling.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T11:06:04.679514Z",
     "start_time": "2019-03-15T11:06:04.499665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you mean elaborate?\n"
     ]
    }
   ],
   "source": [
    "# test spell check\n",
    "print(spell_check(\"elobarate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
